{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbokUxrYW6JU",
    "outputId": "995e309b-aca6-4890-8b3d-0a2f56045739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext cython\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyRYejGKXKU6"
   },
   "source": [
    "## **LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdpjLQR_W86u",
    "outputId": "8ea3cb3d-fd01-43fd-e82e-582381156821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MIzPOzkvXFhw"
   },
   "outputs": [],
   "source": [
    "DATASET_FOLDER = (\"/content/drive/MyDrive/PROYEK STBI/MQ2008/Fold1\")\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'ndcg@10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "d8I_CzcVZ7Eg"
   },
   "outputs": [],
   "source": [
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "    return train_file, valid_file, test_file\n",
    "\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NpIO4mekaCdC"
   },
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, qid):\n",
    "        self.qid = qid\n",
    "        self.labels_to_docs = {}\n",
    "    def addlabel(self, label):\n",
    "        if not label in self.labels_to_docs:\n",
    "            self.labels_to_docs[label] = list()\n",
    "    def adddoc(self, label, doc):\n",
    "        self.labels_to_docs[label].append(doc)\n",
    "    def finalize(self, alllabels):\n",
    "        self.labels = np.zeros(len(self.labels_to_docs.keys()), dtype=int)\n",
    "        self.docs = np.empty(len(self.labels_to_docs.keys()), dtype=object)\n",
    "        i = 0\n",
    "        totaldocs = 0\n",
    "        sorteddict = sorted(self.labels_to_docs.items(), reverse = True)\n",
    "        for label, docs in sorteddict:\n",
    "            self.labels[i] = label\n",
    "            self.docs[i] = np.zeros(len(docs), dtype=int)\n",
    "            for j in range(len(docs)):\n",
    "                self.docs[i][j] = docs[j]\n",
    "            i += 1\n",
    "            totaldocs += len(docs)\n",
    "        self.alldocs = np.concatenate(self.docs)\n",
    "        self.flatlabels = np.zeros(totaldocs, dtype=np.double)\n",
    "        i = 0\n",
    "        for label, docs in sorteddict:\n",
    "            for j in range(len(docs)):\n",
    "                self.flatlabels[i] = label\n",
    "                i += 1       \n",
    "        k = min(10, len(self.alldocs))\n",
    "        self.idealdcg = dcg_k(self.alldocs, alllabels, k) \n",
    "        del self.labels_to_docs\n",
    "    def setperms(self, perms):\n",
    "        self.perms = perms\n",
    "    def setndcgs(self, ndcgs):\n",
    "        self.ndcgs = ndcgs\n",
    "    def __repr__(self):  \n",
    "        return str(self)\n",
    "    def __str__(self):\n",
    "        res = \"Query \" + str(self.qid) + \"[\"\n",
    "        res += \"\\nideal dcg: \" + str(self.idealdcg)\n",
    "        for i in range(len(self.labels)):\n",
    "            res += \"\\n\" + str(self.labels[i]) + \" -> \" + str(self.docs[i])\n",
    "        res += \"]\"\n",
    "        if hasattr(self, 'perms'):\n",
    "            for i in range(len(self.perms)):\n",
    "                res += \"\\n[\" + str(self.perms[i]) + \"] -> dcg: \" + str(self.ndcgs[i])\n",
    "        else:\n",
    "            res += \"\\nNo permutations computed yet\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "40T4A25FaFdk"
   },
   "outputs": [],
   "source": [
    "def mapQueryToDocuments(dataset):\n",
    "    queries = {}\n",
    "    alllabels = np.negative(np.ones(len(dataset[2]), dtype=np.double))\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in queries:\n",
    "            queries[dataset[2][i]] = Query(dataset[2][i])\n",
    "        query = queries[dataset[2][i]]\n",
    "        query.addlabel(dataset[1][i])\n",
    "        query.adddoc(dataset[1][i], i)\n",
    "        alllabels[i] = dataset[1][i]\n",
    "        \n",
    "    for q in queries.values():\n",
    "        q.finalize(alllabels)\n",
    "    \n",
    "    return queries, alllabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkam9ltnVvRH"
   },
   "source": [
    "## **Rank sample set generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQ7_QLcTVnU7",
    "outputId": "4ecc32b2-1946-4dfb-e043-fe59e360939f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4RxjCc1PaI8A"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log2\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double* E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double* energy = <double *> malloc(m*sizeof(double))\n",
    "    cdef double res_w_S, factor \n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            res_w_S = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if k < j: \n",
    "                    res_w_S = res_w_S + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    res_w_S = res_w_S + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j] = factor * res_w_S\n",
    "    return energy\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double[:,:] probs, double[:] accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double* en\n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid] = exp(-en[pos]) # e^{-E}\n",
    "            accumulator[doc] = accumulator[doc] + probs[doc][rankid] # sum(e^{-E})\n",
    "        free(en)\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid] = probs[doc][rankid] / accumulator[doc]\n",
    "        \n",
    "\n",
    "#NDCG EVALUATION\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double dcg_k(int[:] rank, double[:] scores, int k) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(k, schedule='static', num_threads=8):\n",
    "        result += (2**scores[rank[i]] - 1) / (log2(i + 2)) # should be i+1, but with numbering starting from 1 instead of 0\n",
    "    return result\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double ndcg_k(int[:] rank, double[:] scores, int k, double ideal) nogil:\n",
    "    if ideal == 0:\n",
    "        return 1.0\n",
    "    return dcg_k(rank, scores, k) / ideal\n",
    "\n",
    "\n",
    "#PERMUTATIONS GENERATION\n",
    "\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.30 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.22 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.10 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef bint contained(int[:,:] container, int[:] array) nogil:\n",
    "    cdef bint match\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    for i in prange(len(container), schedule='static', num_threads=8):\n",
    "        if container[i][0] == -1 or len(container[i]) != len(array):\n",
    "            continue\n",
    "        else:\n",
    "            match = True\n",
    "            for j in range(len(container[i])):\n",
    "                if container[i][j] != array[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void setrow(int[:,:] container, int pos, int[:] array) nogil:\n",
    "    cdef int i\n",
    "    for i in prange(len(container[pos]), schedule='static', num_threads=8):\n",
    "        container[pos][i] = array[i]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int[:,:] allPerms(int[:] source, long long fact):\n",
    "    cdef int i = 0\n",
    "    cdef int k\n",
    "    perm = itertools.permutations(source)\n",
    "    cdef int[:,:] result = np.zeros((fact, len(source)), dtype=int)\n",
    "    for p in perm:\n",
    "        for k in range(len(p)):\n",
    "            result[i][k] = p[k]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def perform_permutation(query, int i, int j, int count, int[:,:] perms, int start):\n",
    "    if not i in query.labels or not j in query.labels:\n",
    "        # no swapping possible\n",
    "        return count, start\n",
    "    # find the indexes of the desired labels\n",
    "    i = [k for k in range(len(query.labels)) if query.labels[k] == i][0]\n",
    "    j = [k for k in range(len(query.labels)) if query.labels[k] == j][0]\n",
    "    cdef int c = 0\n",
    "    cdef int _min = min(len(query.docs[i]), len(query.docs[j]))\n",
    "    cdef int amount = max(1, int(_min * .5))\n",
    "    limit = factorial(_min) / (factorial(amount) * factorial(_min - amount))\n",
    "    cdef int k\n",
    "    cdef int d\n",
    "    for k in range(count):\n",
    "        perm = query.docs.copy()\n",
    "        first = random.sample(range(len(query.docs[i])), k=amount)\n",
    "        second = random.sample(range(len(query.docs[j])), k=amount)\n",
    "        for d in range(len(first)):\n",
    "            perm[i][first[d]], perm[j][second[d]] = query.docs[j][second[d]], query.docs[i][first[d]]\n",
    "        p = np.concatenate(perm)\n",
    "        if not contained(perms, p):\n",
    "            setrow(perms, start + c, p)\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c, start + c\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0, start + c\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def process_query(query, alllabels, probs, accumulator):\n",
    "    cdef int carry = 0\n",
    "    fact = factorial(len(query.alldocs))\n",
    "    cdef perms\n",
    "    cdef int last = 0\n",
    "    if fact <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms = allPerms(query.alldocs, fact)\n",
    "    else:\n",
    "        perms = np.negative(np.ones((RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS, len(query.alldocs)), dtype=int))\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry, last = perform_permutation(query, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms, last)\n",
    "        if carry != 0:\n",
    "            if not query.alldocs in perms:\n",
    "                perms[last] = query.alldocs\n",
    "        perms = perms[perms.max(axis=1)>=0]\n",
    "    query.setperms(perms)  \n",
    "    P(perms, alllabels, probs, accumulator)\n",
    "    cdef double[:] ndcgs = np.zeros(len(perms))\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in range(len(perms)):\n",
    "        ndcgs[i] = ndcg_k(perms[i], alllabels, k, query.idealdcg)\n",
    "    query.setndcgs(ndcgs)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9PMJUQRU2oH",
    "outputId": "37ff3e7a-994c-4891-a623-132e98a6dfcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: /content/drive/MyDrive/PROYEK STBI/MQ2008/Fold1/train.txt\n",
      "validation file: /content/drive/MyDrive/PROYEK STBI/MQ2008/Fold1/vali.txt\n",
      "test file: /content/drive/MyDrive/PROYEK STBI/MQ2008/Fold1/test.txt\n",
      "loading datasets... \n",
      "train dataset loading took 0.30285060999999835 s\n",
      "validation dataset loading took 0.09325055100000057 s\n",
      "test dataset loading took 0.08717540700000015 s\n",
      "converting datasets to LightGBM format... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "import time\n",
    "start = time.process_time()\n",
    "train_dataset = loadDataset(train_file)\n",
    "print(\"train dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "print(\"validation dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "test_dataset = loadDataset(test_file)\n",
    "print(\"test dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "\n",
    "import itertools\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciQm5bE9V5Oo",
    "outputId": "1f2cfb88-b363-4100-c3e3-20e73ba31ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query-documents mappings...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "train_id = file_len(train_file)\n",
    "vali_id = file_len(valid_file)\n",
    "test_id = file_len(test_file)\n",
    "ds_to_queries = {}\n",
    "ds_to_queries[train_id] = mapQueryToDocuments(train_dataset)\n",
    "ds_to_queries[vali_id] = mapQueryToDocuments(valid_dataset)\n",
    "ds_to_queries[test_id] = mapQueryToDocuments(test_dataset)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlUsLXmocies",
    "outputId": "d74b3644-9e1c-4550-8c1a-1990a807c3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sample sets...\n",
      "sample set creation took 0.0001798969999988742 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"creating sample sets...\")\n",
    "start = time.process_time()\n",
    "\n",
    "probs_with_labels = {}\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "for ds_id, queries in ds_to_queries.items():\n",
    "    probs_with_labels[ds_id] = np.zeros((len(queries[1]), RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS))\n",
    "    accumulator = np.zeros(len(queries[1]))\n",
    "    for q in queries[0].values():\n",
    "        process_query(q, queries[1], probs_with_labels[ds_id], accumulator)    \n",
    "    del accumulator\n",
    "    \n",
    "print(\"sample set creation took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ldUGKWsdiPW"
   },
   "source": [
    "## **BoltzRank logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "xo6h0us8dmy1"
   },
   "outputs": [],
   "source": [
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double** E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double** energy = <double **> malloc(m*sizeof(double*)) # freed at 78\n",
    "    cdef double derivative, first_sum, second_sum, factor\n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            energy[j][0] = 0\n",
    "            energy[j][1] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            derivative = 0.0\n",
    "            first_sum = 0.0\n",
    "            second_sum = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if j > k:\n",
    "                    derivative = derivative + (j - k)\n",
    "                    first_sum = first_sum + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    derivative = derivative + (j - k)\n",
    "                    second_sum = second_sum + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j][0] = factor * (first_sum + second_sum)\n",
    "            energy[j][1] = factor * derivative\n",
    "    return energy\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double*** probs, double** accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double** en\n",
    "    \n",
    "    for pos in range(len(Rq[0])):\n",
    "        doc = Rq[0][pos]\n",
    "        probs[doc] = <double **> malloc(len(Rq)*sizeof(double*)) # freed at 138\n",
    "        accumulator[doc] = <double *> malloc(3*sizeof(double*)) # freed at 136\n",
    "        accumulator[doc][0] = 0\n",
    "        accumulator[doc][1] = 0\n",
    "        accumulator[doc][2] = 0\n",
    "        for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "            probs[doc][rankid] = <double *> malloc(3*sizeof(double)) # freed at 138\n",
    "            \n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid][0] = exp(-en[pos][0]) # e^{-E}\n",
    "            probs[doc][rankid][1] = 0\n",
    "            probs[doc][rankid][2] = en[pos][1] # E'\n",
    "            accumulator[doc][0] = accumulator[doc][0] + probs[doc][rankid][0] # sum(e^{-E})\n",
    "            accumulator[doc][1] = accumulator[doc][1] + (-en[pos][1] * probs[doc][rankid][0]) # sum(-E' * e^{-E})\n",
    "            accumulator[doc][2] = accumulator[doc][2] + ((en[pos][1]**2) * probs[doc][rankid][0]) # sum(E'^2 * e^{-E})\n",
    "            free(en[pos]) # allocated at 28\n",
    "        free(en) # allocated at 24\n",
    "\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid][0] = probs[doc][rankid][0] / accumulator[doc][0]\n",
    "        \n",
    "        # -P * (E' + (sum(-E' * e^{-E}) / sum(e^{-E})))\n",
    "        probs[doc][rankid][1] = -probs[doc][rankid][0] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))\n",
    "                \n",
    "        # -P' * (E' + (sum(-E' * e^{-E}) / sum(e^{-E}))) - P * (1 + (sum(E'^2 * e^{-E}) / sum(-E' * e^{-E})) - (sum(-E' * e^{-E})^2 / sum(e^{-E})^2))\n",
    "        probs[doc][rankid][2] = (-probs[doc][rankid][1] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))) \n",
    "        probs[doc][rankid][2] = probs[doc][rankid][2] + (-probs[doc][rankid][0] * (1 + ((accumulator[doc][2] / accumulator[doc][0]) - (accumulator[doc][1]**2 / accumulator[doc][0]**2))))\n",
    "        \n",
    "        free(accumulator[doc])\n",
    "        \n",
    "    @boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True) \n",
    "cdef void loss_function(int[:,:] Rq, double*** probs, double[:] ndcgs, double** gains, double[:,:] probs_with_labels, double** entropies) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][i]\n",
    "        gains[doc] = <double*> malloc(3*sizeof(double)) # freed at 163\n",
    "        gains[doc][0] = 0\n",
    "        gains[doc][1] = 0\n",
    "        gains[doc][2] = 0\n",
    "        entropies[doc] = <double*> malloc(3*sizeof(double)) # freed at 164\n",
    "        entropies[doc][0] = 0\n",
    "        entropies[doc][1] = 0\n",
    "        entropies[doc][2] = 0\n",
    "        for j in range(len(Rq)):\n",
    "            gains[doc][0] = gains[doc][0] + probs[doc][j][0] * ndcgs[j]\n",
    "            gains[doc][1] = gains[doc][1] + probs[doc][j][1] * ndcgs[j]\n",
    "            gains[doc][2] = gains[doc][2] + probs[doc][j][2] * ndcgs[j]\n",
    "            \n",
    "            # P(L)log(P(S))\n",
    "            entropies[doc][0] = entropies[doc][0] + probs_with_labels[doc][j] * log(probs[doc][j][0])\n",
    "            # P(L)(P'(S)/P(S))\n",
    "            entropies[doc][1] = entropies[doc][1] + (probs_with_labels[doc][j] * probs[doc][j][1] / probs[doc][j][0])\n",
    "            # P(L)(P(S)P''(S)-P'(S)^2)/P(S)^2\n",
    "            entropies[doc][2] = entropies[doc][2] + (probs_with_labels[doc][j] * ((probs[doc][j][0] * probs[doc][j][2] - probs[doc][j][1]**2) / probs[doc][j][0]**2))\n",
    "                                \n",
    "            free(probs[doc][j]) # allocated at 65\n",
    "\n",
    "        free(probs[doc]) # allocated at 62\n",
    "        \n",
    "    # Boltzrank grads and hess evaluation function.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank_grads(queries, S, probs_with_labels): \n",
    "    cdef double lam = .9\n",
    "    cdef double[:] gain = np.ones_like(S)\n",
    "    cdef double[:] hess = np.ones_like(S) \n",
    "    \n",
    "    cdef int i\n",
    "    cdef double*** probs = <double***> malloc(len(S)*sizeof(double**)) # freed at 167\n",
    "    cdef double** accumulator = <double**> malloc(len(S)*sizeof(double*)) # freed at 168\n",
    "    cdef double** gains = <double**> malloc(len(S)*sizeof(double*)) # freed at 165\n",
    "    cdef double** entropies = <double**> malloc(len(S)*sizeof(double*)) # freed at 166\n",
    "    for q in queries.values():\n",
    "        P(q.perms, S, probs, accumulator)\n",
    "        loss_function(q.perms, probs, q.ndcgs, gains, probs_with_labels, entropies)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = (lam * gains[i][1]) - ((1-lam) * -entropies[i][1])\n",
    "        hess[i] = (lam * gains[i][2]) - ((1-lam) * -entropies[i][2])\n",
    "        free(gains[i]) # allocated at 108\n",
    "        free(entropies[i]) # allocated at 130\n",
    "    free(gains) # allocated at 154\n",
    "    free(entropies) # allocated at 155\n",
    "    free(probs) # allocated at 152\n",
    "    free(accumulator) # allocated at 153\n",
    "    return gain, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d39eG3QcdrX5"
   },
   "outputs": [],
   "source": [
    "def compute_grads(preds, train_data): \n",
    "    global ds_to_queries\n",
    "    global train_id\n",
    "    global probs_with_labels\n",
    "    gain, hess = eval_boltzrank_grads(ds_to_queries[train_id][0], preds, probs_with_labels[train_id])\n",
    "    gain = np.asarray(gain)\n",
    "    hess = np.asarray(hess)\n",
    "    #print(\"PREDS: min \" + str(np.min(preds)) + \" max \" + str(np.max(preds)) + \" mean \" + str(np.mean(preds)) + \" std \" + str(np.std(preds)))\n",
    "    #print(\"GAIN: min \" + str(np.min(gain)) + \" max \" + str(np.max(gain)) + \" mean \" + str(np.mean(gain)) + \" std \" + str(np.std(gain)))\n",
    "    #print(\"HESS: min \" + str(np.min(hess)) + \" max \" + str(np.max(hess)) + \" mean \" + str(np.mean(hess)) + \" std \" + str(np.std(hess)))\n",
    "    return gain, hess\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],# ['None']\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "print(\"training lightgbm...\")\n",
    "start = time.process_time()\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            fobj  = compute_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "print(\"training took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")\n",
    "# Plot the results\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Listwise Learning to Rank Approach using BoltzRank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
